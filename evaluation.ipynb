{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7cd81ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "PROJECT_ID = '...'\n",
        "LOCATION = '...'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "994dc008",
      "metadata": {},
      "outputs": [],
      "source": [
        "from src.evaluator.evaluator import (\n",
        "    init_vertexai,\n",
        "    run_subjective_evaluation,\n",
        "    run_free_form_evaluation,\n",
        "    run_rubric_evaluation,\n",
        ")\n",
        "from src.data import get_evaluation_dataset\n",
        "\n",
        "# from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "\n",
        "init_vertexai(\n",
        "    project_id=PROJECT_ID,\n",
        "    location=LOCATION\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f877de91",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 評価対象データを取得する。\n",
        "input_data = get_evaluation_dataset()\n",
        "\n",
        "# 評価を実行する。\n",
        "for i, data in enumerate(input_data):\n",
        "    print(f\"\\n{'='*20} Data {i+1} (ID: {data.get('prompt_id', 'N/A')}) {'='*20}\\n\")\n",
        "    \n",
        "    # 会話履歴の構築\n",
        "    conversation = \"\"\n",
        "    for p in data['prompts']:\n",
        "        conversation += f\"{p['role']}: {p['content']}\\n\"\n",
        "    conversation += f\"assistant: {data['llm_response_text']}\"\n",
        "    \n",
        "    rubrics = data['rubrics']\n",
        "    \n",
        "    print(\"--- 1. Subjective Evaluation (主観評価) ---\")\n",
        "    print(run_subjective_evaluation(conversation))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"--- 2. Free Form Evaluation (自由記述評価) ---\")\n",
        "    print(run_free_form_evaluation(conversation, rubrics))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print(\"--- 3. Rubric Evaluation (ルーブリック評価) ---\")\n",
        "    for r in rubrics:\n",
        "        result = run_rubric_evaluation(conversation, r)\n",
        "        print(f\"Rubric: {r['criterion']} (Points: {r['points']})\")\n",
        "        print(f\"Result: {result}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
